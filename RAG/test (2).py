import json
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer, CrossEncoder

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EMBED_MODEL   = "BAAI/bge-m3"
RERANK_MODEL  = "cross-encoder/ms-marco-MiniLM-L-6-v2"
INDEX_PATH    = "embeddb/index_cpu.faiss"
META_PATH     = "embeddb/metadata.jsonl"

# 1ì°¨ FAISS ê²€ìƒ‰ ì‹œë„í•  top_n, rerankí•  rerank_n
TOP_K         = 5
INITIAL_K     = 50    # first-pass FAISS ì—ì„œ ë½‘ì•„ì˜¬ ê°œìˆ˜
NP            = 64    # IVF.nprobe

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. ëª¨ë¸ & ì¸ë±ìŠ¤ ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ğŸ”„  ë¡œë“œ ì¤‘â€¦")
embedder    = SentenceTransformer(EMBED_MODEL, device="cpu")
reranker    = CrossEncoder(RERANK_MODEL, device="cpu")
index       = faiss.read_index(INDEX_PATH)
index.nprobe = NP

# ë©”íƒ€ ì „ì²´ë¥¼ ë¯¸ë¦¬ ì½ì–´ ë‘ë©´ ë¹ ë¦…ë‹ˆë‹¤
with open(META_PATH, encoding="utf-8") as f:
    metas = [json.loads(line) for line in f]

print(f"âœ…  ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {index.ntotal} vectors, nprobe={NP}")
print("ë©”íƒ€ ë°ì´í„° ê°œìˆ˜:", len(metas))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. ê²€ìƒ‰+ë¦¬ë­í¬ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def search_and_rerank(query: str, top_k: int = TOP_K, init_k: int = INITIAL_K):
    # 1) ì¿¼ë¦¬ ì„ë² ë”©
    qv = embedder.encode([query], normalize_embeddings=True).astype(np.float32)

    # 2) FAISS ê²€ìƒ‰
    D0, I0 = index.search(qv, init_k)
    idxs0 = I0[0].tolist()

    # 3) Cross-Encoder rerank
    rerank_inputs = [(query, metas[i]['content']) for i in idxs0]
    scores_rerank = reranker.predict(rerank_inputs)
    # ì •ë ¬
    reranked = sorted(zip(idxs0, scores_rerank), key=lambda x: x[1], reverse=True)[:top_k]

    # 4) ê²°ê³¼
    results = []
    for idx, sc in reranked:
        meta = metas[idx].copy()
        results.append((float(sc), meta))
    return results

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    print("ğŸ¯ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸â€”ì›í•˜ëŠ” ë¬¸ì¥ì„ ì…ë ¥í•˜ê³  ì—”í„°ë¥¼ ëˆŒëŸ¬ ë³´ì„¸ìš”. ë¹ˆ ì…ë ¥ ì‹œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    while True:
        query = input("\nê²€ìƒ‰ì–´ â–¶ ").strip()
        if not query:
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        hits = search_and_rerank(query)
        print(f"\nğŸ” Top-{len(hits)} ê²°ê³¼:")
        for rank, (score, meta) in enumerate(hits, start=1):
            print(f"\n{rank:>2}. score={score:.4f}")
            print(f"   â€¢ source_file: {meta['source_file']}")
            print(f"   â€¢ type       : {meta['type']}")
            if meta['type']=="íŠ¹í—ˆ":
                print(f"   â€¢ patent_id  : {meta['patent_id']}")
                print(f"   â€¢ section    : {meta['section']} / {meta['subsection']}")
                print(f"   â€¢ claim#     : {meta['claim_number']}")
                print(f"   â€¢ status     : {meta['status']}")
            print(f"   â€¢ title      : {meta.get('ë°œëª…ì˜_ëª…ì¹­','')}")
            print(f"   â€¢ content    : {meta['content'][:200]}...")  # ì• 200ìë§Œ



import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# 1) FAISS ì¸ë±ìŠ¤ ë¡œë“œ
index = faiss.read_index("embeddb/index_cpu.faiss")
index.nprobe = 64  # ê²€ìƒ‰ ì†ë„/ì •í™•ë„ ë°¸ëŸ°ìŠ¤

# 2) Bi-Encoder (BGE-M3) ëª¨ë¸ ë¡œë“œ
be_model = SentenceTransformer("BAAI/bge-m3", device="cuda")
be_model.eval()

# 3) Cross-Encoder ëª¨ë¸ ë¡œë“œ
ce_tokenizer = AutoTokenizer.from_pretrained("cross-encoder/ms-marco-MiniLM-L-12-v2")
ce_model     = AutoModelForSequenceClassification.from_pretrained("cross-encoder/ms-marco-MiniLM-L-12-v2")
ce_model.to("cuda").eval()

def retrieve_and_rerank(query: str,
                        top_k_faiss: int = 100,
                        top_n_final: int = 10):
    # (1) Bi-Encoder ì„ë² ë”©
    q_emb = be_model.encode([query], convert_to_numpy=True, normalize_embeddings=True)
    # (2) FAISS ê²€ìƒ‰
    D, I = index.search(q_emb, top_k_faiss)  # distances, indices

    # (3) í›„ë³´ ë¬¸ì¥ë“¤ ë¡œë“œ
    #    â€” ë¯¸ë¦¬ meta_gpu*.jsonl ì—ì„œ line ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ë°°ì—´ë¡œ ë©”ëª¨ë¦¬ì— ìºì‹œí•´ ë‘ì„¸ìš”
    #    meta_lines[i] = ê²€ìƒ‰ ê²°ê³¼ ië²ˆ ë²¡í„°ì˜ ì›ë¬¸ í…ìŠ¤íŠ¸
    candidates = [ meta_lines[idx] for idx in I[0] ]

    # (4) Cross-Encoder ì¬ìˆœìœ„
    inputs = ce_tokenizer(
        [query]*len(candidates),
        candidates,
        padding=True, truncation=True, return_tensors="pt"
    ).to("cuda")
    with torch.no_grad():
        scores = ce_model(**inputs).logits.squeeze(-1)  # [batch]
    topk = torch.topk(scores, k=top_n_final)

    return [(candidates[i], float(scores[i])) for i in topk.indices.cpu().numpy()]

# ì‚¬ìš© ì˜ˆ
if __name__ == "__main__":
    # â€” ë¯¸ë¦¬ ë©”íƒ€ ë¡œë“œ
    with open("embeddb/meta_all.jsonl", encoding="utf-8") as f:
        meta_lines = [json.loads(l)["text"] for l in f]

    query = "ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ ì•ˆêµ¬ì§ˆë³‘ ì§„ë‹¨ ë°©ë²•"
    results = retrieve_and_rerank(query, top_k_faiss=200, top_n_final=5)
    for text, score in results:
        print(f"{score:.3f}\t{text}")

