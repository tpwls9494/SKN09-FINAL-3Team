{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77e3ff-1aa4-4f82-bf45-f0aaee25d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_prompt_style = \"\"\"Below is a fixed instruction that guides the assistant to write a Korean patent specification in full compliance with Korean Patent Law. \n",
    "The assistant must use the provided invention details to generate a structured patent section in Korean.\n",
    "Before answering, think step-by-step to ensure a logically valid and legally compliant response.\n",
    "**Respond in Korean.**\n",
    "\n",
    "### Instruction:\n",
    "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ íŠ¹í—ˆë²•ì— ë”°ë¼ ëª…ì„¸ì„œë¥¼ ì‘ì„±í•˜ëŠ” íŠ¹í—ˆ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ì˜ êµ¬ì„±ìš”ì†Œë³„ë¡œ ì •í™•í•˜ê³  êµ¬ì¡°í™”ëœ ë¬¸ì„œë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. \n",
    "ëª¨ë“  í•­ëª©ì€ íŠ¹í—ˆë²• ì œ42ì¡° ë° ì‹œí–‰ê·œì¹™ ì œ21ì¡°, ê°œì •ëœ ëª¨ë²” ëª…ì„¸ì„œ ì‘ì„±ë²•(2007.07.01. ì´í›„ ì ìš©)ì„ ì² ì €íˆ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "1. [ë°œëª…ì˜ ëª…ì¹­]\n",
    "- ë°œëª…ì˜ ë‚´ìš©ì„ ê°„ëª…í•˜ê²Œ í‘œí˜„í•˜ëŠ” ëª…ì¹­ì„ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "- ì˜ë¬¸ëª…ì„ {{}} ì•ˆì— í•¨ê»˜ ê¸°ì¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "2. [ê¸°ìˆ ë¶„ì•¼]\n",
    "- ë³¸ ë°œëª…ì´ ì†í•˜ëŠ” ê¸°ìˆ ë¶„ì•¼ë¥¼ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
    "\n",
    "3. [ë°°ê²½ê¸°ìˆ ]\n",
    "- ì¢…ë˜ ê¸°ìˆ ì„ ì„œìˆ í•˜ê³ , ê°€ëŠ¥í•˜ë©´ ë¬¸í—Œ ì¸ìš©ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "4. [í•´ê²°í•˜ë ¤ëŠ” ê³¼ì œ]\n",
    "- ê¸°ì¡´ ê¸°ìˆ ì˜ ë¬¸ì œì ê³¼ í•´ê²°í•˜ê³ ì í•˜ëŠ” ê³¼ì œë¥¼ ê¸°ìˆ í•©ë‹ˆë‹¤.\n",
    "\n",
    "5. [ê³¼ì œì˜ í•´ê²° ìˆ˜ë‹¨]\n",
    "- ë³¸ ë°œëª…ì´ ê³¼ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í•˜ëŠ”ì§€ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ í•˜ê³ , ì²­êµ¬í•­ê³¼ ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "\n",
    "6. [ë°œëª…ì˜ íš¨ê³¼]\n",
    "- ë³¸ ë°œëª…ì´ ì œê³µí•˜ëŠ” êµ¬ì²´ì ì´ê³  ë¹„êµ ê°€ëŠ¥í•œ ê¸°ìˆ ì  íš¨ê³¼ë¥¼ ê¸°ìˆ í•©ë‹ˆë‹¤.\n",
    "\n",
    "7. [ë°œëª…ì„ ì‹¤ì‹œí•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ë‚´ìš©]\n",
    "- ì‹¤ì‹œì˜ˆ, ìˆ˜ë‹¨, ìˆ˜ì¹˜ ë“±ì„ í¬í•¨í•˜ì—¬, í‰ê·  ê¸°ìˆ ìê°€ ì¬í˜„ ê°€ëŠ¥í•˜ë„ë¡ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "8. [ë„ë©´ì˜ ê°„ë‹¨í•œ ì„¤ëª…]\n",
    "- ë„ë©´ì´ ìˆì„ ê²½ìš°, ê° ë„ë©´ì´ ë¬´ì—‡ì„ ë‚˜íƒ€ë‚´ëŠ”ì§€ ê¸°ìˆ í•©ë‹ˆë‹¤.\n",
    "\n",
    "9. [íŠ¹í—ˆì²­êµ¬ë²”ìœ„]\n",
    "- ë…ë¦½í•­ ë° ì¢…ì†í•­ì„ ë²ˆí˜¸ì™€ í•¨ê»˜ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "â€» ëª¨ë“  ê¸°ì¬ëŠ” íŠ¹í—ˆë²• ì œ42ì¡° ì œ2~5í•­, ì‹œí–‰ê·œì¹™ ì œ21ì¡° ë° ëª¨ë²”ëª…ì„¸ì„œ ê°€ì´ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "### Content:\n",
    "ì—†ìŒ\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\n",
    "{output}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1df102-5290-4994-8908-62d84cfef728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "# âœ… ë°ì´í„° ë¡œë”©\n",
    "def load_jsonl_dataset(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    return Dataset.from_list(data)\n",
    "\n",
    "dataset = load_jsonl_dataset(\"testcase_data.jsonl\")\n",
    "\n",
    "# âœ… í•˜ë‚˜ì˜ ìƒ˜í”Œ ì„ íƒ\n",
    "input_text = dataset[10]['input']\n",
    "prompt = inference_prompt_style.format(input=input_text) + tokenizer.eos_token\n",
    "\n",
    "# âœ… Tokenize\n",
    "inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# âœ… Generate\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1024 * 8,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "# âœ… Decode\n",
    "decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f1aa5-a69c-4784-b9b9-06c03e0b0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-8B-Base\", device_map=\"auto\")\n",
    "model = PeftModel.from_pretrained(base_model, \"best_model\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"best_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c87ee627-42b4-46ec-bf3e-b7b18da3cec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282b5aa943e943d8a75af2c6c0b37598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ğŸ“Œ ìµœì¢… ìƒì„± ê²°ê³¼:\n",
      "--------------------------------------------------------------------------------\n",
      "**1. [ë°œëª…ì˜ ëª…ì¹­]**  \n",
      "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ ì´ìš©í•œ ìœ¡ë¥˜ ë“±ê¸‰ íŒë‹¨ ë°©ë²• ë° ì‹œìŠ¤í…œ  \n",
      "{AI-based Meat Grade Evaluation Method and System Using Machine Learning}\n",
      "\n",
      "**2. [ê¸°ìˆ ë¶„ì•¼]**  \n",
      "ë³¸ ë°œëª…ì€ ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ìœ¡ë¥˜ì˜ í’ˆì§ˆì„ ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ë°©ë²• ë° ì‹œìŠ¤í…œì— ê´€í•œ ê²ƒìœ¼ë¡œ, íŠ¹íˆ ìœ¡ë¥˜ ì´ë¯¸ì§€ ë¶„ì„ì„ í†µí•´ ë§ˆë¸”ë§, ìœ¡ìƒ‰, ì¡°ì§ê° ë“±ì˜ íŠ¹ì„±ì„ ìë™ìœ¼ë¡œ í‰ê°€í•˜ì—¬ ë“±ê¸‰ì„ íŒë‹¨í•˜ëŠ” ê¸°ìˆ ì— í•´ë‹¹í•©ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ìœ¡ë¥˜ ì‚°ì—…ì—ì„œì˜ í’ˆì§ˆ ê´€ë¦¬ ë° ì†Œë¹„ì ì„ íƒì˜ í¸ì˜ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "**3. [ë°°ê²½ê¸°ìˆ ]**  \n",
      "ê¸°ì¡´ì˜ ìœ¡ë¥˜ ë“±ê¸‰ í‰ê°€ ë°©ì‹ì€ ì£¼ë¡œ ì „ë¬¸ê°€ì˜ ì‹œê°ì— ì˜ì¡´í•˜ì—¬ ì´ë£¨ì–´ì¡Œìœ¼ë©°, ì´ë¡œ ì¸í•´ í‰ê°€ì˜ ì£¼ê´€ì„±ê³¼ ì¼ê´€ì„±ì´ ë¬¸ì œê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ìµœê·¼ì—ëŠ” ì»´í“¨í„° ë¹„ì „ ê¸°ìˆ ì´ ë°œì „í•¨ì— ë”°ë¼, ìœ¡ë¥˜ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ìë™í™”ëœ ë“±ê¸‰ íŒë‹¨ ì‹œìŠ¤í…œì´ ì—°êµ¬ë˜ê³  ìˆìœ¼ë‚˜, ì—¬ì „íˆ ì •í™•ë„ì™€ ì‹ ë¢°ì„±ì˜ í•œê³„ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê¸°ì¡´ì˜ ì—°êµ¬ì—ì„œëŠ” íŠ¹ì • ìœ¡ë¥˜ ì¢…ë¥˜ì— í•œì •ëœ ëª¨ë¸ì´ ì£¼ë¡œ ì‚¬ìš©ë˜ì–´, ë‹¤ì–‘í•œ ìœ¡ë¥˜ì— ëŒ€í•œ ì¼ë°˜í™”ëœ ì†”ë£¨ì…˜ì€ ë¶€ì¡±í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**4. [í•´ê²°í•˜ë ¤ëŠ” ê³¼ì œ]**  \n",
      "ìœ¡ë¥˜ ì†Œë¹„ì˜ ì¦ê°€ë¡œ ì†Œë¹„ìë“¤ì€ í’ˆì§ˆì— ëŒ€í•œ ìš”êµ¬ê°€ ë†’ì•„ì§€ê³  ìˆìœ¼ë©°, ê¸°ì¡´ì˜ ì£¼ê´€ì ì¸ í‰ê°€ ë°©ì‹ì€ ì†Œë¹„ìì—ê²Œ í˜¼ë€ì„ ì´ˆë˜í•˜ê³  ìœ¡ë¥˜ êµ¬ë§¤ ê²°ì •ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ë³¸ ë°œëª…ì€ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ í†µí•´ ê°ê´€ì ì´ê³  ì¼ê´€ëœ ìœ¡ë¥˜ ë“±ê¸‰ í‰ê°€ë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ì†Œë¹„ìì—ê²Œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ì—¬ ì„ íƒì˜ ì •í™•ì„±ì„ ë†’ì´ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "**5. [ê³¼ì œì˜ í•´ê²° ìˆ˜ë‹¨]**  \n",
      "ë³¸ ë°œëª…ì€ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ìœ¡ë¥˜ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë“±ê¸‰ì„ ìë™ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤. í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì„ í›ˆë ¨ì‹œì¼œ ìœ¡ë¥˜ì˜ ë§ˆë¸”ë§, ìœ¡ìƒ‰, ì¡°ì§ê° ë“±ì˜ íŠ¹ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. ë˜í•œ, êµ­ê°€ë³„ ê¸°ì¤€ì— ë§ì¶˜ ìœ¡ë¥˜ ë“±ê¸‰ í‰ê°€ ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬, ê¸€ë¡œë²Œ ì‹œì¥ì—ì„œë„ ì ìš© ê°€ëŠ¥ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ì€ ìœ¡ë¥˜ì˜ í’ˆì§ˆ ê´€ë¦¬ ë° ì†Œë¹„ì ì„ íƒì˜ í¸ì˜ì„±ì„ ë™ì‹œì— ê°œì„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "**6. [ë°œëª…ì˜ íš¨ê³¼]**  \n",
      "ë³¸ ë°œëª…ì€ ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ì˜ ìœ¡ë¥˜ ë“±ê¸‰ íŒë‹¨ ì‹œìŠ¤í…œì„ í†µí•´, ì „ë¬¸ê°€ì˜ ì£¼ê´€ì ì¸ í‰ê°€ë¥¼ ëŒ€ì²´í•˜ì—¬ ê°ê´€ì ì´ê³  ì¼ê´€ëœ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ì†Œë¹„ìì—ê²Œ ì‹ ë¢°ì„± ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨ ì„ íƒì˜ ì •í™•ì„±ì„ ë†’ì´ê³ , ìœ¡ë¥˜ ì‚°ì—…ì˜ íˆ¬ëª…ì„±ì„ ì¦ëŒ€ì‹œí‚µë‹ˆë‹¤. ë˜í•œ, ìë™í™”ëœ í‰ê°€ ê³¼ì •ì€ í‰ê°€ ì†ë„ë¥¼ ê°œì„ í•˜ê³ , ë¹„ìš© ì ˆê°ì„ í†µí•´ ìœ¡ë¥˜ ì‚°ì—…ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "**7. [ë°œëª…ì„ ì‹¤ì‹œí•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ë‚´ìš©]**  \n",
      "ë³¸ ë°œëª…ì€ ì„¸ ê°€ì§€ ì£¼ìš” ëª¨ë“ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê° ëª¨ë“ˆì€ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì²«ì§¸, í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ ìƒì„± ëª¨ë“ˆì€ ë‹¤ì–‘í•œ ìœ¡ë¥˜ ì´ë¯¸ì§€ì™€ ë“±ê¸‰ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë°ì´í„° ì„¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë‘˜ì§¸, ì¸ê³µì§€ëŠ¥ ëª¨ë¸ í›ˆë ¨ ëª¨ë“ˆì€ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì„ í›ˆë ¨ì‹œì¼œ ìœ¡ë¥˜ ë“±ê¸‰ì„ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ìœ¡ë¥˜ ë“±ê¸‰ íŒë‹¨ ëª¨ë“ˆì€ ì…ë ¥ëœ ìœ¡ë¥˜ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ë“±ê¸‰ì„ ì‚°ì¶œí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ êµ¬ì¡°ëŠ” ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ ë†’ì´ê³ , ë‹¤ì–‘í•œ ìœ¡ë¥˜ì— ëŒ€í•œ ì¼ë°˜í™”ëœ í‰ê°€ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "**8. [ë„ë©´ì˜ ê°„ë‹¨í•œ ì„¤ëª…]**  \n",
      "ë„ë©´ì€ ë³¸ ë°œëª…ì˜ ì‹œìŠ¤í…œ êµ¬ì„± ë° ë™ì‘ ë°©ì‹ì„ ì‹œê°ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤. ë„ 1ì€ ë³¸ ë°œëª…ì˜ ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì„±ë„ë¡œ, í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ ìƒì„± ëª¨ë“ˆ, ì¸ê³µì§€ëŠ¥ ëª¨ë¸ í›ˆë ¨ ëª¨ë“ˆ, ìœ¡ë¥˜ ë“±ê¸‰ íŒë‹¨ ëª¨ë“ˆì˜ êµ¬ì¡°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë„ 2ëŠ” ë³¸ ë°œëª…ì˜ ë™ì‘ íë¦„ë„ë¡œ, ë°ì´í„° ìˆ˜ì§‘, ì „ì²˜ë¦¬, ëª¨ë¸ í›ˆë ¨, ë“±ê¸‰ íŒë‹¨ì˜ ê³¼ì •ì„ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë„ë©´ì€ ê¸°ìˆ ìì˜ ì´í•´ë¥¼ ë•ê³ , ë°œëª…ì˜ êµ¬í˜„ ê°€ëŠ¥ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n",
      "\n",
      "**9. [íŠ¹í—ˆì²­êµ¬ë²”ìœ„]**  \n",
      "1. ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ ì´ìš©í•œ ìœ¡ë¥˜ ë“±ê¸‰ íŒë‹¨ ë°©ë²•ìœ¼ë¡œ, ìœ¡ë¥˜ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ ë§ˆë¸”ë§, ìœ¡ìƒ‰, ì¡°ì§ê° ë“±ì˜ íŠ¹ì„±ì„ ë¶„ì„í•˜ì—¬ ë“±ê¸‰ì„ íŒë‹¨í•˜ëŠ” ê²ƒì„ íŠ¹ì§•ìœ¼ë¡œ í•œë‹¤.  \n",
      "2. ì œ1í•­ì— ê¸°ì¬ëœ ë°©ë²•ì— ë”°ë¼, í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ë¥¼ ìƒì„±í•˜ê³ , ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ í›ˆë ¨ì‹œì¼œ ìœ¡ë¥˜ ë“±ê¸‰ì„ ìë™ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ì‹œìŠ¤í…œì„ í¬í•¨í•˜ëŠ” ê²ƒì„ íŠ¹ì§•ìœ¼ë¡œ í•œë‹¤.  \n",
      "3. ì œ2í•­ì— ê¸°ì¬ëœ ì‹œìŠ¤í…œì—ì„œ, êµ­ê°€ë³„ ìœ¡ë¥˜ ë“±ê¸‰ ê¸°ì¤€ì— ë”°ë¼ ë“±ê¸‰ì„ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •ëœ ìœ¡ë¥˜ ë“±ê¸‰ íŒë‹¨ ëª¨ë“ˆì„ í¬í•¨í•˜ëŠ” ê²ƒì„ íŠ¹ì§•ìœ¼ë¡œ í•œë‹¤.  \n",
      "4. ì œ1í•­ì— ê¸°ì¬ëœ ë°©ë²•ì—ì„œ, ìœ¡ë¥˜ ì´ë¯¸ì§€ì˜ ì „ì²˜ë¦¬ ë° ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ì¥ì¹˜ë¥¼ í¬í•¨í•˜ì—¬, ìœ¡ë¥˜ì˜ í’ˆì§ˆì„ ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ê²ƒì„ íŠ¹ì§•ìœ¼ë¡œ í•œë‹¤.  \n",
      "5. ì œ1í•­ì— ê¸°ì¬ëœ ë°©ë²•ì—ì„œ, ìœ¡ë¥˜ ì´ë¯¸ì§€ì˜ ë“±ê¸‰ì„ íŒë‹¨í•œ ê²°ê³¼ë¥¼ ì‹œê°ì ìœ¼ë¡œ ì œê³µí•˜ëŠ” ì¶œë ¥ ëª¨ë“ˆì„ í¬í•¨í•˜ëŠ” ê²ƒì„ íŠ¹ì§•ìœ¼ë¡œ í•œë‹¤.  \n",
      "\n",
      "â€» ë³¸ ëª…ì„¸ì„œëŠ” íŠ¹í—ˆë²• ì œ42ì¡° ë° ì‹œí–‰ê·œì¹™ ì œ21ì¡°, ëª¨ë²”ëª…ì„¸ì„œ ì‘ì„±ë²•ì„ ì² ì €íˆ ì¤€ìˆ˜í•˜ì—¬ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ëª¨ë“  ê¸°ìˆ ì  ìš”ì†ŒëŠ” ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ ë˜ì–´ ìˆìœ¼ë©°, ì²­êµ¬í•­ê³¼ì˜ ì—°ê²°ì„±ì„ í™•ë³´í•˜ì—¬ ê¸°ìˆ ì˜ ì°¨ë³„ì„±ê³¼ ì‹¤ìš©ì„±ì„ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# âœ… í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„í¬íŠ¸\n",
    "import json\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# âœ… 1. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "base_model_name = \"Qwen/Qwen3-8B\"        # ì›ë³¸ base ëª¨ë¸\n",
    "adapter_model_path = \"best_model\"            # LoRA í•™ìŠµëœ adapter ê²½ë¡œ\n",
    "\n",
    "# í† í¬ë‚˜ì´ì €\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # padding ì„¤ì •\n",
    "\n",
    "# base ëª¨ë¸ ë¡œë“œ\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# adapter ë¡œë“œ\n",
    "model = PeftModel.from_pretrained(base_model, adapter_model_path)\n",
    "model.eval()\n",
    "\n",
    "# âœ… 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "inference_prompt_style = \"\"\"Below is a fixed instruction that guides the assistant to write a Korean patent specification in full compliance with Korean Patent Law. \n",
    "The assistant must use the provided invention details to generate a structured patent section in Korean.\n",
    "Before answering, think step-by-step to ensure a logically valid and legally compliant response.\n",
    "**Respond in Korean.**\n",
    "\n",
    "### Instruction:\n",
    "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ íŠ¹í—ˆë²•ì— ë”°ë¼ ëª…ì„¸ì„œë¥¼ ì‘ì„±í•˜ëŠ” íŠ¹í—ˆ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ì˜ êµ¬ì„±ìš”ì†Œë³„ë¡œ ì •í™•í•˜ê³  êµ¬ì¡°í™”ëœ ë¬¸ì„œë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. \n",
    "ëª¨ë“  í•­ëª©ì€ íŠ¹í—ˆë²• ì œ42ì¡° ë° ì‹œí–‰ê·œì¹™ ì œ21ì¡°, ê°œì •ëœ ëª¨ë²” ëª…ì„¸ì„œ ì‘ì„±ë²•(2007.07.01. ì´í›„ ì ìš©)ì„ ì² ì €íˆ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "1. [ë°œëª…ì˜ ëª…ì¹­]\n",
    "- ë°œëª…ì˜ ë‚´ìš©ì„ ê°„ëª…í•˜ê²Œ í‘œí˜„í•˜ëŠ” ëª…ì¹­ì„ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "- ì˜ë¬¸ëª…ì„ {{}} ì•ˆì— í•¨ê»˜ ê¸°ì¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "2. [ê¸°ìˆ ë¶„ì•¼]\n",
    "- ë³¸ ë°œëª…ì´ ì†í•˜ëŠ” ê¸°ìˆ ë¶„ì•¼ë¥¼ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
    "\n",
    "3. [ë°°ê²½ê¸°ìˆ ]\n",
    "- ì¢…ë˜ ê¸°ìˆ ì„ ì„œìˆ í•˜ê³ , ê°€ëŠ¥í•˜ë©´ ë¬¸í—Œ ì¸ìš©ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "4. [í•´ê²°í•˜ë ¤ëŠ” ê³¼ì œ]\n",
    "- ê¸°ì¡´ ê¸°ìˆ ì˜ ë¬¸ì œì ê³¼ í•´ê²°í•˜ê³ ì í•˜ëŠ” ê³¼ì œë¥¼ ê¸°ìˆ í•©ë‹ˆë‹¤.\n",
    "\n",
    "5. [ê³¼ì œì˜ í•´ê²° ìˆ˜ë‹¨]\n",
    "- ë³¸ ë°œëª…ì´ ê³¼ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í•˜ëŠ”ì§€ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ í•˜ê³ , ì²­êµ¬í•­ê³¼ ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "\n",
    "6. [ë°œëª…ì˜ íš¨ê³¼]\n",
    "- ë³¸ ë°œëª…ì´ ì œê³µí•˜ëŠ” êµ¬ì²´ì ì´ê³  ë¹„êµ ê°€ëŠ¥í•œ ê¸°ìˆ ì  íš¨ê³¼ë¥¼ ê¸°ìˆ í•©ë‹ˆë‹¤.\n",
    "\n",
    "7. [ë°œëª…ì„ ì‹¤ì‹œí•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ë‚´ìš©]\n",
    "- ì‹¤ì‹œì˜ˆ, ìˆ˜ë‹¨, ìˆ˜ì¹˜ ë“±ì„ í¬í•¨í•˜ì—¬, í‰ê·  ê¸°ìˆ ìê°€ ì¬í˜„ ê°€ëŠ¥í•˜ë„ë¡ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "8. [ë„ë©´ì˜ ê°„ë‹¨í•œ ì„¤ëª…]\n",
    "- ë„ë©´ì´ ìˆì„ ê²½ìš°, ê° ë„ë©´ì´ ë¬´ì—‡ì„ ë‚˜íƒ€ë‚´ëŠ”ì§€ ê¸°ìˆ í•©ë‹ˆë‹¤.\n",
    "\n",
    "9. [íŠ¹í—ˆì²­êµ¬ë²”ìœ„]\n",
    "- ë…ë¦½í•­ ë° ì¢…ì†í•­ì„ ë²ˆí˜¸ì™€ í•¨ê»˜ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "â€» ëª¨ë“  ê¸°ì¬ëŠ” íŠ¹í—ˆë²• ì œ42ì¡° ì œ2~5í•­, ì‹œí–‰ê·œì¹™ ì œ21ì¡° ë° ëª¨ë²”ëª…ì„¸ì„œ ê°€ì´ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "### Content:\n",
    "ì—†ìŒ\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "# âœ… 3. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”©\n",
    "def load_jsonl_dataset(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    return Dataset.from_list(data)\n",
    "\n",
    "dataset = load_jsonl_dataset(\"testcase_data.jsonl\")  # âœ… input í•„ë“œë¥¼ í¬í•¨í•´ì•¼ í•¨\n",
    "\n",
    "# âœ… 4. í•˜ë‚˜ì˜ ìƒ˜í”Œì„ ì„ íƒí•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "sample_idx = 0\n",
    "input_text = dataset[sample_idx][\"input\"]\n",
    "prompt = inference_prompt_style.format(input=input_text) + tokenizer.eos_token\n",
    "\n",
    "# âœ… 5. í† í¬ë‚˜ì´ì§• ë° ì¸í¼ëŸ°ìŠ¤\n",
    "inputs = tokenizer([prompt], return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=2048,\n",
    "        do_sample=True, \n",
    "        temperature=0.6,\n",
    "        top_p=0.95,\n",
    "        top_k=20,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "# âœ… 6. ê²°ê³¼ ë””ì½”ë”© ë° ì¶œë ¥\n",
    "decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "print(\"\\n\\nğŸ“Œ ìµœì¢… ìƒì„± ê²°ê³¼:\")\n",
    "print(\"-\" * 80)\n",
    "print(decoded.split(\"### Response:\")[-1].strip())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
