import json
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
index_path = "vectordb/cleaned_law_bge_m3_index.faiss"
meta_path = "vectordb/cleaned_law_bge_m3_metadata.jsonl"
model_name = "BAAI/bge-m3"

# ëª¨ë¸ ë¡œë“œ
print("[1] ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
model = SentenceTransformer(model_name)

# FAISS ì¸ë±ìŠ¤ ë¡œë“œ
print("[2] FAISS ì¸ë±ìŠ¤ ë¡œë”©...")
index = faiss.read_index(index_path)

# ë©”íƒ€ë°ì´í„° ë¡œë“œ
print("[3] ë©”íƒ€ë°ì´í„° ë¡œë”©...")
texts = []
with open(meta_path, "r", encoding="utf-8") as f:
    for line in f:
        item = json.loads(line.strip())
        texts.append(item["text"])

# ì‚¬ìš©ì ì…ë ¥
query = "ë“±ë¡ ì›ë¶€ ì‘ì„±ì— í•„ìš”í•œ ì„œì‹ì€?"
print(f"[4] ì¿¼ë¦¬ ì…ë ¥: {query}")

# ì¿¼ë¦¬ ì„ë² ë”©
query_vec = model.encode([query], normalize_embeddings=True)

# Top-K ìœ ì‚¬í•œ ê²°ê³¼ ê²€ìƒ‰
k = 5
scores, indices = index.search(np.array(query_vec), k)

print("\n[5] ğŸ” ê²€ìƒ‰ ê²°ê³¼ (Top 5)")
for i, idx in enumerate(indices[0]):
    print(f"\n[{i+1}] ìœ ì‚¬ë„: {scores[0][i]:.4f}")
    print(texts[idx])
